# Quantification {#quantification}

One key initial step in analyzing RNA-seq data is to quantify,
or estimate, the number of fragments in the experiment that 
can be assigned to each feature, whether a gene or a transcript
(an isoform of a gene). Alongside quantification, it is strongly
recommended to perform quality control (QC) checks on the sequence
files. Reports spanning multiple samples can be generated with 
the [MultiQC](https://multiqc.info/) software [@Ewels2016]. Here 
I will not start with quality control checks, but instead move 
straight to quantification and import of estimated counts into R,
although an example quality control report can be found in the 
*airway2* package on GitHub: 
[MultiQC report](https://github.com/mikelove/airway2/blob/master/inst/extdata/multiqc_report.html).

The data I will examine first in this section is from an experiment
of the effect of knocking down OCT4 and BRG1 in mouse embryos [@King2017].
In particular, I will examine the treatment effect of knocking down OCT4.
The experiment had four groups of samples, each replicated in
triplicate. The RNA-seq data from the experiment is available in the
*oct4* Bioconductor package.

I will use the *Salmon* software for estimating transcript abundance [@Patro2017].
Briefly, *Salmon* uses the sequenced reads and the reference transcripts,
and constructs a generative model for the observed data, which includes
modeling of various technical biases that are commonly observed in RNA-seq.
*Salmon* then outputs the estimated counts for each transcript, and an "effective length"
of the transcript, which is shorter than the full length of the transcript
if it was biased to having fewer reads due to technical artifact, and longer 
than the full length of the transcript if it was biased to having more reads.
For details about the Salmon method and software, refer to the 
[Salmon website](https://combine-lab.github.io/salmon/).

All 12 samples from the experiment were re-quantified using *Salmon*. 
The jobs for processing the reads with Salmon were executed via 
Snakemake [@Koster2012], a convinient tool for scheduling and 
executing repetative rule-based operations on input data.
The exact lines of code can be seen in the
[Snakefile](https://github.com/mikelove/oct4/blob/master/inst/scripts/Snakefile).

Most of the packages shown in this online book live within the Bioconductor
project [@Huber2015]. Bioconductor objects are more complex than
basic objects in R, for example *numberic*, *character*, or other 
simple objects, in that they often have attached metadata, such as
additional information about rows and columns, or other metadata.
We will see how to make use of the metadata throughout the various
sections by examining, e.g. `colData` for information about the columns
of a matrix, or `mcols` for metadata columns.

I begin by loading some data in the Bioconductor package *oct4*.
Note that this step is not useful for a typical RNA-seq workflow,
as the data will not be contained in an R package, but contained
in some directory on a server or compute cluster. So in lieu
of the `system.file` command below, which is used here to locate
a file within an R package, you could just specify the `dir` 
variable to be a path to the files, e.g. `/path/to/data/dir`.

```{r sysdir}
dir <- system.file("extdata", package="oct4")
list.files(dir)
```

I will use the *readr* and *dplyr* packages to read in a CSV
file with information about the samples. Because we are typically
working with tall count matrices, with the rows representing
genomic features such as genes or transcripts, and columns 
representing samples, the sample information is referred to
as the column data or `coldata`. For more information on 
dplyr, see the excellent 
[dplyr online documentation](https://dplyr.tidyverse.org/).

```{r coldata}
library(readr)
coldata <- read_csv(file.path(dir,"coldata.csv"))
```

I next set the `levels` of the `line` and `condition` factor variables
so that `OCT4` and `untrt` are the reference levels, and I specify
the path to the quantification files I want to read in.

In the last step of the `mutate` call, note I specify paths to the
quantification files `quant.sf.gz`. Typically, these files are not
gzipped, but I have compressed the `quant.sf` files to reduce the 
size of the data package. Note also that, although I point only to the
`quant.sf` files, the entire directory containing that file
is required for proper import of the quantification data. 
There are other metadata files that provide important information a
bout the experiment, including uncertainty information. The
metadata files enable automatic identification of the feature set,
a computational reproducibility feature that will be described later 
in this section.

```{r dplyr}
suppressPackageStartupMessages(library(dplyr))
coldata <- coldata %>% 
  mutate(line=factor(line, levels=c("OCT4","BRG1")),
         condition=factor(condition, levels=c("untrt","trt")),
         files=file.path(dir, "quants", names, "quant.sf.gz"))
```

All the files exist at the locations I specified, which in this case
have the pattern `/<DIR>/quants/<NAMES>/quant.sf.gz`.

```{r file-exists}
all(file.exists(coldata$files))
```

I will now use the Bioconductor package *tximeta* [@Love2019] to 
read in the quantification data, and create a *SummarizedExperiment*
object. The *SummarizedExperiment* object is described in @Huber2015,
in particular diagrammed in 
[Figure 2](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4509590/figure/F2/).
Here, the `tximeta` function perform a number of operations on the 
behalf of the user, identifying the reference transcripts that were used
to quantify the RNA-seq reads, automatically downloading (or loading)
the relevant genomic locations of the transcripts, and attaching the
relevant genomic context (the genome version and chromosome names and 
lengths). *tximeta* can perform these operations by leveraging the
hash signature of the sequence of the transcripts, which is stored
when processing bulk RNA-seq with *Salmon*, or when processing single
cell RNA-seq with the *alevin* software [@Srivastava2019]
(distributed with *Salmon*).

A small note: I specify `dropInfReps=TRUE`, because I will be
performing gene-level analysis, and I won't make use of the
uncertainty information in this first analysis. I will show 
in a later section how to make use of the inferential replicates
computed by *Salmon* during quantification.

```{r load-txi}
library(tximeta)
```

```{r load-se}
suppressPackageStartupMessages(library(SummarizedExperiment))
```

```{r tximeta, cache=TRUE}
se <- tximeta(coldata, dropInfReps=TRUE)
```

In the above output, we can see that `tximeta` identified that
the mouse reference transcripts, release M20, was used from
GENCODE [@GENCODE]. This information would be automatically 
identified, even if the group that performed the quantification
did not document this when uploading to a public repository.

We can see the matrices of data that have been compiled, and 
examine the genomic locations of the features (rows):

```{r look-se}
assayNames(se)
rowRanges(se)
```

Because the `tximeta` function has identified the correct 
reference transcripts that were used for quantification,
and stored this as metadata in the *SummarizedExperiment* 
object, I can obtain additional information, such as the 
mapping of transcripts to genes. I can then perform a summarization
task, without having to look up this mapping manually.

```{r summarize, cache=TRUE}
gse <- summarizeToGene(se)
```

Gene-level summarization of transcript-level quantification data
is described in the methods paper for *tximport* [@Soneson2015].
The `tximeta` function internally calls methods from the
*tximport* package during its operation. Note that *tximport*
provides similar functionality to *tximeta*, but instead of 
returning a rich Bioconductor object, *tximport* returns
a simple list of matrices.

Below I show some examples of operations that can be easily
performed because I have a *SummarizedExperiment* object
with the appropriate gene ranges attached. I can easily
subset the genes (rows) based on overlaps with a given genomic range 
using standard square bracket indexing. The range-based
class system and set of methods for operating on genomic ranges
is provided by the *GenomicRanges* package, which has useful
help pages and vignettes [@Lawrence2013].

```{r ranges}
rowRanges(gse)
x <- GRanges("chr1", IRanges(10e6, 11e6))
gse[gse %over% x, ]
```

I can likewise easily subset the samples by referring to 
the `colData` columns, e.g. `colData(gse)$line`. 
A shortcut for referring to `colData` columns is to just use 
the dollar sign directly on the object, `gse$line`.

```{r column-select}
gse[, gse$line == "OCT4"]
```

Finally, I demonstrate that it is easily to add alternative
identifiers, making use of the organism annotation packages
in Bioconductor. For example, to add gene symbols, I can 
use *tximeta*'s `addIds` function, and specify the `SYMBOL`
column. 

```{r addids}
library(org.Mm.eg.db)
gse <- addIds(gse, column="SYMBOL")
```

To check all the available columns for an organism package,
use the `columns` function:

```{r org-columns}
columns(org.Mm.eg.db)
```
