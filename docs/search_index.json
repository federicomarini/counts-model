[
["index.html", "Statistical Modeling of High Dimensional Counts About this online book", " Statistical Modeling of High Dimensional Counts Michael I. Love 2020-02-03 About this online book This online book is a chapter of a physical book about RNA Bioinformatics. Here I will describe how count data, as often arises in RNA sequencing (RNA-seq) experiments, can be modeled using count distributions, as well as how nonparametric methods can be used to analyze count data. The book will cover basic routines for performing data input, scaling/normalization, visualization, and statistical testing to determine sets of features where the counts reflect differences in expression across samples. The final section will cover limitations of the methods presented and extensions. The code in this book includes the basic routines that can be found in software vignettes of various Bioconductor packages, including tximeta, DESeq2, and fishpond. Please see those package vignettes for further details. Any specific questions about Bioconductor software should be posted to the Bioconductor support site: https://support.bioconductor.org There are also two published workflows that are related to the analysis steps and packages described here, but which explore different directions. These workflows are hosted on the Bioconductor workflow site, and checked regularly to ensure they build correctly and without error: rnaseqGene - gene-level exploratory analysis and differential expression (Love et al. 2015) rnaseqDTU - differential transcript usage (Love, Soneson, and Patro 2018) Another related reference is Van den Berge et al. (2019), which is a review of RNA-seq expression analysis, written by a collection of researchers who develop statistical models and software for RNA-seq data. References "],
["quantification.html", "Chapter 1 Quantification", " Chapter 1 Quantification One key initial step in analyzing RNA-seq data is to quantify, or estimate, the number of fragments in the experiment that can be assigned to each feature, whether a gene or a transcript (an isoform of a gene). Alongside quantification, it is strongly recommended to perform quality control (QC) checks on the sequence files. Reports spanning multiple samples can be generated with the MultiQC software (Ewels et al. 2016). Here I will not start with quality control checks, but instead move straight to quantification and import of estimated counts into R, although an example quality control report can be found in the airway2 package on GitHub: MultiQC report. The data I will examine first in this section is from an experiment of the effect of knocking down OCT4 and BRG1 in mouse embryos (King and Klose 2017). In particular, I will examine the treatment effect of knocking down OCT4. The experiment had four groups of samples, each replicated in triplicate. The RNA-seq data from the experiment is available in the oct4 Bioconductor package. I will use the Salmon software for estimating transcript abundance (Patro et al. 2017). Briefly, Salmon uses the sequenced reads and the reference transcripts, and constructs a generative model for the observed data, which includes modeling of various technical biases that are commonly observed in RNA-seq. Salmon then outputs the estimated counts for each transcript, and an “effective length” of the transcript, which is shorter than the full length of the transcript if it was biased to having fewer reads due to technical artifact, and longer than the full length of the transcript if it was biased to having more reads. For details about the Salmon method and software, refer to the Salmon website. All 12 samples from the experiment were quantified using Salmon. The jobs for processing the reads with Salmon were executed via Snakemake (Köster and Rahmann 2012), a convenient tool for scheduling and executing repetitive rule-based operations on input data. The exact lines of code can be seen in the Snakefile. Most of the packages shown in this online book live within the Bioconductor project (Huber et al. 2015). Bioconductor objects are more complex than basic objects in R, for example numeric, character, or other simple objects, in that they often have attached metadata, such as additional information about rows and columns, or other metadata. We will see how to make use of the metadata throughout the various sections by examining, e.g. colData for information about the columns of a matrix, or mcols for metadata columns. I begin by loading some data in the Bioconductor package oct4. Note that this step is not useful for a typical RNA-seq workflow, as the data will not be contained in an R package, but contained in some directory on a server or compute cluster. So in lieu of the system.file command below, which is used here to locate a file within an R package, you could just specify the dir variable to be a path to the files, e.g. /path/to/data/dir. dir &lt;- system.file(&quot;extdata&quot;, package=&quot;oct4&quot;) list.files(dir) ## [1] &quot;coldata.csv&quot; &quot;list&quot; &quot;quants&quot; ## [4] &quot;SraRunTable.txt&quot; I will use the readr and dplyr packages to read in a CSV file with information about the samples. Because we are typically working with “tall” count matrices, with the rows representing genomic features such as genes or transcripts, and columns representing samples, the sample information is referred to as the column data or coldata. For more information on dplyr, see the excellent dplyr online documentation. library(readr) coldata &lt;- read_csv(file.path(dir,&quot;coldata.csv&quot;)) ## Parsed with column specification: ## cols( ## names = col_character(), ## line = col_character(), ## condition = col_character() ## ) I next set the levels of the line and condition factor variables so that OCT4 and untrt are the reference levels, and I specify the path to the quantification files I want to read in. In the last step of the mutate call, note I specify paths to the quantification files quant.sf.gz. Typically, these files are not gzipped, but I have compressed the quant.sf files to reduce the size of the data package. Note also that, although I point only to the quant.sf files, the entire directory containing that file is required for proper import of the quantification data. There are other metadata files that provide important information about the experiment, including uncertainty information. The metadata files enable automatic identification of the feature set, a computational reproducibility feature that will be described later in this section. suppressPackageStartupMessages(library(dplyr)) coldata &lt;- coldata %&gt;% mutate(line=factor(line, levels=c(&quot;OCT4&quot;,&quot;BRG1&quot;)), condition=factor(condition, levels=c(&quot;untrt&quot;,&quot;trt&quot;)), files=file.path(dir, &quot;quants&quot;, names, &quot;quant.sf.gz&quot;)) All the files exist at the locations I specified, which in this case have the pattern /&lt;DIR&gt;/quants/&lt;NAMES&gt;/quant.sf.gz. all(file.exists(coldata$files)) ## [1] TRUE I will now use the Bioconductor package tximeta (Love et al. 2019) to read in the quantification data, and create a SummarizedExperiment object. The SummarizedExperiment class is described in Huber et al. (2015), in particular diagrammed in this figure. Here, the tximeta function perform a number of operations on behalf of the user, identifying the reference transcripts that were used to quantify the RNA-seq reads, automatically downloading (or loading) the relevant genomic locations of the transcripts, and attaching the relevant genomic context (the genome version and chromosome names and lengths). tximeta can perform these operations by leveraging the hash signature of the sequence of the transcripts, which is stored when processing bulk RNA-seq with Salmon, or when processing single cell RNA-seq with the alevin software (A. Srivastava, Malik, Smith, et al. 2019) (distributed with Salmon). A small note: I specify dropInfReps=TRUE, because I will be performing gene-level analysis, and I won’t make use of the uncertainty information in this first analysis. I will show in a later section how to make use of the inferential replicates computed by Salmon during quantification. library(tximeta) ## Warning: package &#39;tximeta&#39; was built under R version 3.6.2 suppressPackageStartupMessages(library(SummarizedExperiment)) se &lt;- tximeta(coldata, dropInfReps=TRUE) ## importing quantifications ## reading in files with read_tsv ## 1 2 3 4 5 6 7 8 9 10 11 12 ## found matching transcriptome: ## [ GENCODE - Mus musculus - release M20 ] ## loading existing TxDb created: 2019-07-01 19:31:02 ## loading existing transcript ranges created: 2019-09-12 12:45:55 ## fetching genome info for GENCODE In the above output, we can see that tximeta identified that the mouse reference transcripts, release M20, were used from GENCODE (Frankish, GENCODE-consoritum, and Flicek 2018). This information would be automatically identified, even if the group that performed the quantification did not document this when uploading processed expression data to a public repository. We can see the matrices of data that have been compiled, and examine the genomic locations of the features (rows): assayNames(se) ## [1] &quot;counts&quot; &quot;abundance&quot; &quot;length&quot; rowRanges(se) ## GRanges object with 137271 ranges and 3 metadata columns: ## seqnames ranges strand | ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | ## ENSMUST00000193812.1 chr1 3073253-3074322 + | ## ENSMUST00000082908.1 chr1 3102016-3102125 + | ## ENSMUST00000162897.1 chr1 3205901-3216344 - | ## ENSMUST00000159265.1 chr1 3206523-3215632 - | ## ENSMUST00000070533.4 chr1 3214482-3671498 - | ## ... ... ... ... . ## ENSMUST00000082419.1 chrM 13552-14070 - | ## ENSMUST00000082420.1 chrM 14071-14139 - | ## ENSMUST00000082421.1 chrM 14145-15288 + | ## ENSMUST00000082422.1 chrM 15289-15355 + | ## ENSMUST00000082423.1 chrM 15356-15422 - | ## tx_id gene_id ## &lt;integer&gt; &lt;CharacterList&gt; ## ENSMUST00000193812.1 1 ENSMUSG00000102693.1 ## ENSMUST00000082908.1 2 ENSMUSG00000064842.1 ## ENSMUST00000162897.1 4203 ENSMUSG00000051951.5 ## ENSMUST00000159265.1 4204 ENSMUSG00000051951.5 ## ENSMUST00000070533.4 4205 ENSMUSG00000051951.5 ## ... ... ... ## ENSMUST00000082419.1 138833 ENSMUSG00000064368.1 ## ENSMUST00000082420.1 138834 ENSMUSG00000064369.1 ## ENSMUST00000082421.1 138825 ENSMUSG00000064370.1 ## ENSMUST00000082422.1 138826 ENSMUSG00000064371.1 ## ENSMUST00000082423.1 138835 ENSMUSG00000064372.1 ## tx_name ## &lt;character&gt; ## ENSMUST00000193812.1 ENSMUST00000193812.1 ## ENSMUST00000082908.1 ENSMUST00000082908.1 ## ENSMUST00000162897.1 ENSMUST00000162897.1 ## ENSMUST00000159265.1 ENSMUST00000159265.1 ## ENSMUST00000070533.4 ENSMUST00000070533.4 ## ... ... ## ENSMUST00000082419.1 ENSMUST00000082419.1 ## ENSMUST00000082420.1 ENSMUST00000082420.1 ## ENSMUST00000082421.1 ENSMUST00000082421.1 ## ENSMUST00000082422.1 ENSMUST00000082422.1 ## ENSMUST00000082423.1 ENSMUST00000082423.1 ## ------- ## seqinfo: 22 sequences (1 circular) from mm10 genome Because the tximeta function has identified the correct reference transcripts that were used for quantification, and stored this as metadata in the SummarizedExperiment object, I can obtain additional information, such as the correspondence of transcripts to genes. I can then perform a summarization task, without having to look up this information manually. gse &lt;- summarizeToGene(se) ## loading existing TxDb created: 2019-07-01 19:31:02 ## obtaining transcript-to-gene mapping from TxDb ## loading existing gene ranges created: 2019-07-01 19:32:20 ## summarizing abundance ## summarizing counts ## summarizing length Gene-level summarization of transcript-level quantification data is described in the paper for tximport (Soneson, Love, and Robinson 2015). The tximeta function internally calls methods from the tximport package during its operation. Note that tximport provides similar functionality to tximeta, but instead of returning a rich Bioconductor object, tximport returns a simple list of matrices. Below I show some examples of operations that can be easily performed because I have a SummarizedExperiment object with the appropriate gene ranges attached. I can easily subset the genes (rows) based on overlaps with a given genomic range using standard square bracket indexing. The range-based class system and set of methods for operating on genomic ranges is provided by the GenomicRanges package, which has useful help pages and vignettes (Lawrence et al. 2013). rowRanges(gse) ## GRanges object with 53697 ranges and 1 metadata column: ## seqnames ranges strand | ## &lt;Rle&gt; &lt;IRanges&gt; &lt;Rle&gt; | ## ENSMUSG00000000001.4 chr3 108107280-108146146 - | ## ENSMUSG00000000003.15 chrX 77837901-77853623 - | ## ENSMUSG00000000028.15 chr16 18780447-18811987 - | ## ENSMUSG00000000031.16 chr7 142575529-142578143 - | ## ENSMUSG00000000037.16 chrX 161117193-161258213 + | ## ... ... ... ... . ## ENSMUSG00000117651.1 chr17 32731010-32731806 + | ## ENSMUSG00000117652.1 chr18 6910459-6936621 - | ## ENSMUSG00000117653.1 chr17 94811611-94812922 - | ## ENSMUSG00000117654.1 chr17 32863662-32877942 - | ## ENSMUSG00000117655.1 chr19 57497390-57512784 + | ## gene_id ## &lt;character&gt; ## ENSMUSG00000000001.4 ENSMUSG00000000001.4 ## ENSMUSG00000000003.15 ENSMUSG00000000003.15 ## ENSMUSG00000000028.15 ENSMUSG00000000028.15 ## ENSMUSG00000000031.16 ENSMUSG00000000031.16 ## ENSMUSG00000000037.16 ENSMUSG00000000037.16 ## ... ... ## ENSMUSG00000117651.1 ENSMUSG00000117651.1 ## ENSMUSG00000117652.1 ENSMUSG00000117652.1 ## ENSMUSG00000117653.1 ENSMUSG00000117653.1 ## ENSMUSG00000117654.1 ENSMUSG00000117654.1 ## ENSMUSG00000117655.1 ENSMUSG00000117655.1 ## ------- ## seqinfo: 22 sequences (1 circular) from mm10 genome x &lt;- GRanges(&quot;chr1&quot;, IRanges(10e6, 11e6)) gse[gse %over% x, ] ## class: RangedSummarizedExperiment ## dim: 18 12 ## metadata(6): tximetaInfo quantInfo ... txomeInfo txdbInfo ## assays(3): counts abundance length ## rownames(18): ENSMUSG00000025916.10 ENSMUSG00000025917.9 ## ... ENSMUSG00000103448.1 ENSMUSG00000103810.1 ## rowData names(1): gene_id ## colnames(12): SRX2236945 SRX2236946 ... SRX2236955 ## SRX2236956 ## colData names(3): names line condition I can likewise easily subset the samples by referring to the colData columns, e.g. colData(gse)$line. A shortcut for referring to colData columns is to just use the dollar sign directly on the object, gse$line. gse[, gse$line == &quot;OCT4&quot;] ## class: RangedSummarizedExperiment ## dim: 53697 6 ## metadata(6): tximetaInfo quantInfo ... txomeInfo txdbInfo ## assays(3): counts abundance length ## rownames(53697): ENSMUSG00000000001.4 ## ENSMUSG00000000003.15 ... ENSMUSG00000117654.1 ## ENSMUSG00000117655.1 ## rowData names(1): gene_id ## colnames(6): SRX2236945 SRX2236946 ... SRX2236949 ## SRX2236950 ## colData names(3): names line condition Finally, I demonstrate that it is easy to add alternative identifiers, making use of the organism annotation packages in Bioconductor. For example, to add gene symbols, I can use tximeta’s addIds function, and specify the SYMBOL column. library(org.Mm.eg.db) ## Loading required package: AnnotationDbi ## ## Attaching package: &#39;AnnotationDbi&#39; ## The following object is masked from &#39;package:dplyr&#39;: ## ## select ## gse &lt;- addIds(gse, column=&quot;SYMBOL&quot;) ## mapping to new IDs using &#39;org.Mm.eg.db&#39; data package ## if all matching IDs are desired, and &#39;1:many mappings&#39; are reported, ## set multiVals=&#39;list&#39; to obtain all the matching IDs ## it appears the rows are gene IDs, setting &#39;gene&#39; to TRUE ## &#39;select()&#39; returned 1:many mapping between keys and ## columns To check all the available columns for an organism package, use the columns function: columns(org.Mm.eg.db) ## [1] &quot;ACCNUM&quot; &quot;ALIAS&quot; &quot;ENSEMBL&quot; &quot;ENSEMBLPROT&quot; ## [5] &quot;ENSEMBLTRANS&quot; &quot;ENTREZID&quot; &quot;ENZYME&quot; &quot;EVIDENCE&quot; ## [9] &quot;EVIDENCEALL&quot; &quot;GENENAME&quot; &quot;GO&quot; &quot;GOALL&quot; ## [13] &quot;IPI&quot; &quot;MGI&quot; &quot;ONTOLOGY&quot; &quot;ONTOLOGYALL&quot; ## [17] &quot;PATH&quot; &quot;PFAM&quot; &quot;PMID&quot; &quot;PROSITE&quot; ## [21] &quot;REFSEQ&quot; &quot;SYMBOL&quot; &quot;UNIGENE&quot; &quot;UNIPROT&quot; References "],
["model.html", "Chapter 2 Counts modeling 2.1 A first exploration of counts 2.2 Modeling counts with DESeq2 2.3 Hypothesis weighting", " Chapter 2 Counts modeling 2.1 A first exploration of counts In this section, I will discuss the statistical models that are often used to analyze RNA-seq data, in particular gene-level count matrices. I will then use the DESeq2 package to calculate scaling factors, estimate biological dispersion within groups of samples, and perform differential testing per gene (Love, Huber, and Anders 2014). Some other popular Bioconductor packages for RNA-seq analysis include the edgeR package (Robinson, McCarthy, and Smyth 2010; McCarthy, Chen, and Smyth 2012) and the limma-voom method in the limma package (Law et al. 2014). The approach taken by DESeq2 for estimation of dispersion is similar to the method proposed by Wu, Wang, and Wu (2012) in the DSS Bioconductor package. I will begin by investigating the estimated counts that were imported from the Salmon software, and comparing these counts across and within samples. I will note the varying precision that the counts offer for log ratio comparisons between samples. Finally, I will perform per-gene testing for differential expression using the DESeq2 package, and multiple test correction, including the IHW method (Ignatiadis et al. 2016). Note that the first section of this chapter includes code and plots that are not typically performed during RNA-seq analysis, but mostly for introducing the reader to some basic properties of RNA-seq count matrices. First, it’s useful to explore the varying number of fragments (pairs of reads) that have been assigned to the genes for each sample. For a typical mammalian RNA-seq experiment, we might expect tens of millions of fragments per sample, which are distributed across tens of thousands of genes, although there is inevitably a range of sequencing depth for each sample: assayNames(gse) ## [1] &quot;counts&quot; &quot;abundance&quot; &quot;length&quot; cs &lt;- colSums(assay(gse, &quot;counts&quot;)) hist(cs/1e6, col=&quot;grey&quot;, border=&quot;white&quot;, main=&quot;&quot;, xlab=&quot;column sums (per million)&quot;) Let us first consider just two samples, one from the OCT4 untreated group and one from the OCT4 treated group. I will make a plot examining the proportion of the total count for each gene. I will first subset to only those genes where both samples have a count of 5 or more, to cut down on the number of points to plot. Here I use the total count, colSums(cts) to divide the counts for each sample, while later we will discuss a robust estimator for sequencing depth variation across samples. Before I create the proportions, it’s important to remember that, because genes with longer transcripts will produce more cDNA fragments, the proportion estimated here (without taking into account the length of the feature) does not estimate the proportion of molecules. The abundance assay of the gse object contains estimates of the proportions of the molecules, in transcripts per million (TPM). For more on how these estimates are computed, consult the Salmon paper (Patro et al. 2017). cts &lt;- assay(gse, &quot;counts&quot;)[,c(1,4)] idx &lt;- rowSums(cts &gt;= 5) == 2 cts &lt;- cts[idx,] p &lt;- sweep(cts, 2, colSums(cts), &quot;/&quot;) We can examine the ratio of the proportions for each gene, over the geometric mean, using the maplot function from the rafalib package. We will plot the ratio and the geometric mean of proportions both on the log scale. maplot is a basic function for making an “MA-plot” which has been used in transcriptomics since at least the early 2000s when it was used for microarray datasets (Dudoit et al. 2002; Roberts et al. 2000). Later I will show a specialized MA-plot function for RNA-seq data in DESeq2. library(rafalib) ## ## Attaching package: &#39;rafalib&#39; ## The following object is masked from &#39;package:devtools&#39;: ## ## install_bioc maplot(log10(p[,1]), log10(p[,2]), n=nrow(p), cex=.3, col=rgb(0,0,0,.2), xlab=&quot;log10 proportion (geometric mean)&quot;, ylab=&quot;log10 fold change&quot;) abline(h=0, col=rgb(0,0,1,.5)) The red line is a smooth curve through the log ratios (here \\(\\log_{10}\\), although we will later switch to \\(\\log_2\\) for more interpretable ratios). Note that the line is relatively flat across many orders of magnitude of the proportion. So whether the gene has 1 millionth of the total count (-6) or up to one thousandth of the total count (-3), the ratio between the two samples tends to fluctuate around 0, with most of the points somewhere between -0.1 and 0.1. The points further off the horizontal line may indicate differentially expressed genes, but we will better identify these using all of the replicates. While just considering the two samples, I can also examine the histogram of the x-axis above, the mean of the \\(\\log_{10}\\) proportions (or equivalently the \\(\\log_{10}\\) of the geometric mean of proportions). We see that most genes that we are considering fall in the range from 1/10,000,000 (-7) to 1/10,000 (-4) of the total count. That these ratios are very low is relevant for the choice of statistical distribution for the counts. mean.log.p &lt;- rowMeans(log10(p)) hist(mean.log.p, col=&quot;grey&quot;, border=&quot;white&quot;, main=&quot;&quot;, xlab=&quot;log10 proportion (geometric mean)&quot;) library(rafalib) maplot(log10(p[,1]), log10(p[,2]), n=nrow(p), xlim=c(-6.5, -3.5), ylim=c(-2,2), cex=.3, col=rgb(0,0,0,.2), xlab=&quot;log10 proportion (geometric mean)&quot;, ylab=&quot;log10 fold change&quot;) abline(h=0, col=rgb(0,0,1,.5)) I will zoom out on the y-axis and zoom in on the x-axis on the MA-plot to emphasize that, for the range containing most of the genes, the middle of the distribution of the ratio of proportions across the treatment is centered on 0. The base of \\(10\\) is not a great choice for the logarithm, because it’s not common to have a 10 fold change, and then it becomes hard to interpret the meaningful changes in the range from 0 to 1. Much better is to use \\(\\log_2\\), as we can easily interpret 1 as doubling, 2 as quadrupling, etc. Now I calculate the \\(\\log_2\\) ratio of proportions and plot the histogram of these log ratios, for genes where the log10 mean proportion is between -6 and -4: lfc &lt;- log2(p[,2]) - log2(p[,1]) hist(lfc[between(mean.log.p, -6, -4)], breaks=seq(-10,10,by=.1), xlim=c(-5,5), col=&quot;grey50&quot;, border=&quot;white&quot;, main=&quot;&quot;, xlab=&quot;log2 fold change of proportion&quot;) Again we see that it’s rare for there to be an extreme change (more than doubling) comparing these two samples from different treatment groups. Most of the genes fall around 0. Exactly 0 implies no change in the proportion as calculated using the total count. Before we begin modeling the counts from the RNA-seq experiment, I produce one more plot to give a sense of expected sampling variation with counts of a similar distribution to the ones we observed. Supposing that the proportions p was fixed for the first sample, and we draw 30,000,000 fragments according to these gene-wise proportions. We would then obtain a multinomial distribution for the counts per gene. When the number of observations is large, and the proportions are small, the count for any given gene is well approximated by a Poisson distribution. So I will create two simulated technical replicate samples, by creating two draws from a Poisson distribution along the genes. I then repeat the same code as above, to examine the MA-plot for the simulated counts. sim.cts &lt;- matrix(rpois(nrow(p) * 2, 30e6 * p[,1]), ncol=2) colSums(sim.cts) ## [1] 30001346 29996359 idx &lt;- rowSums(sim.cts &gt;= 5) == 2 sim.cts &lt;- sim.cts[idx,] sim.p &lt;- sweep(sim.cts, 2, colSums(sim.cts), &quot;/&quot;) maplot(log10(sim.p[,1]), log10(sim.p[,2]), n=nrow(p), cex=.3, col=rgb(0,0,0,.2), xlab=&quot;log10 proportion (geometric mean)&quot;, ylab=&quot;log10 fold change&quot;) abline(h=0, col=rgb(0,0,1,.5)) Note that, even after filtering out genes that do not have a count of 5 or more for both samples, there is still substantial variance for the ratio of proportions for the small count genes compared to the large count genes. 2.2 Modeling counts with DESeq2 I will now demonstrate the use of the DESeq2 package for estimating per-sample scaling factors, per-gene dispersion and fold changes per gene across the samples. As in edgeR and limma, DESeq2 allows for the use of complex designs, leveraging R’s formula syntax. For details about various design formula, first consult the DESeq2 vignette and ?results help page. I create a DESeqDataSet object, by providing the gene-level SummarizedExperiment object, and specifying the design, which is a formula expressing how we wish to model the counts. Here, I specify a baseline term for each line (OCT4 or BRG1), and a condition effect specific to each line (so comparing treated vs untreated, specific to each line). The colon between line and condition specifies to form an interaction between those two terms. library(DESeq2) dds &lt;- DESeqDataSet(gse, design=~line + line:condition) ## using counts and average transcript lengths from tximeta After creating the dataset, I perform some minimal filtering that makes sense for bulk RNA-seq. I filter such that there must be at least three samples with a count of 10 or more to keep the gene in the dataset. This will reduce the size of the dataset (here, removing more than half of the genes) and the time needed to fit various per-gene parameters, such as dispersion and fold change estimates. keep &lt;- rowSums(counts(dds) &gt;= 10) &gt;= 3 table(keep) ## keep ## FALSE TRUE ## 30173 23524 dds &lt;- dds[keep,] The parameters are estimated with a single call to the DESeq function. For details on all the steps performed by this function, check the help page ?DESeq, as well as a section of the vignette called, ``The DESeq2 model’’. Briefly, DESeq2 computes a robust size factor which outperforms the total count in adjusting for differential sequence depth across libraries. Then DESeq2 computes (iteralively) the coefficients of a generalized linear model (GLM), and a dispersion parameter that reflects the variation in addition to the Poisson variation, around the expected value for each sample conditioned on information in the design matrix. dds &lt;- DESeq(dds) ## estimating size factors ## using &#39;avgTxLength&#39; from assays(dds), correcting for library size ## estimating dispersions ## gene-wise dispersion estimates ## mean-dispersion relationship ## final dispersion estimates ## fitting model and testing One of the key estimates is the dispersion for each gene. DESeq2 uses a combination of methods to estimate the dispersion. First, the gene-wise estimate is produced using the methods proposed by edgeR in 2012 for a Negative Binomial generalized linear model (GLM) (McCarthy, Chen, and Smyth 2012). Briefly, the maximum adjusted profile likelihood estimate is calculated, where the adjustment of Cox and Reid (1987) is used to avoid a downward bias on the dispersion estimate. This bias adjustment is similar in theory to the the use of \\(\\frac{1}{n-1}\\) in estimating the sample variance. Below I plot the estimates over the mean of scaled counts for each gene. Note that many of the plots in DESeq2 refer to “normalized counts”; here this just implies scaling the counts by the size factor, so that the differences affecting counts across samples are minimized. There are two per-gene estimates, an initial estimate which looks only at the data for a single gene (gene-est, black points), and a final estimate that incorporates information from each gene, as well as sharing information across genes (final, blue points). The blue circles at the top of the plot represent genes with high dispersion relative to the rest of the dataset, and in these cases, only the gene-est estimate is used, without information from other genes. plotDispEsts(dds, ylim=c(1e-3, .5), xlim=c(5,1e5)) Below I will continue with per-gene analysis, but first, I demonstrate how to examine differences across the most variable genes using a PCA plot. Before I compute the principal components, I use the vst function to compute a variance stabilizing transformation (VST) (Tibshirani 1988) of the count data. This is similar to a log2 transform but avoids inflating the variance of the low count genes. For more details on the methods used here to compute the transformation, consult the DESeq2 vignette or ?vst. The specific VST used by DESeq2 for RNA-seq counts was proposed by the first DESeq paper by Anders and Huber (2010). Another option for performing dimension reduction (as in PCA) on count data is to use the Poisson distance (Witten 2011) or GLM-PCA (Townes et al. 2019). These two alternatives are explored in the gene-level RNA-seq workflow hosted on Bioconductor (Love et al. 2015). Below I specify blind=FALSE which will use the sample grouping information when calculating the per-gene dispersion. The transformation itself does not use the design, once the global dispersion trend has been fit. vsd &lt;- vst(dds, blind=FALSE) plotPCA(vsd, intgroup=c(&quot;line&quot;,&quot;condition&quot;)) We can see that the primary axis of variation among the most variable genes is the cell line difference (OCT4 vs BRG1), and the second axis corresponds to treatment differences, though note that these are not consistent across cell line. I can extract various results tables from the dds object, based on the design. Here I extract a table of results for the effect of condition in the OCT4 line. The summary function will provide a summary table across all genes. We observe more than a thousand genes up- and down-regulated with response to treatment for this comparison, for a false discovery rate (FDR) cutoff of 10%. resultsNames(dds) ## [1] &quot;Intercept&quot; &quot;line_BRG1_vs_OCT4&quot; ## [3] &quot;lineOCT4.conditiontrt&quot; &quot;lineBRG1.conditiontrt&quot; res &lt;- results(dds, name=&quot;lineOCT4.conditiontrt&quot;) summary(res) ## ## out of 23524 with nonzero total read count ## adjusted p-value &lt; 0.1 ## LFC &gt; 0 (up) : 1615, 6.9% ## LFC &lt; 0 (down) : 1932, 8.2% ## outliers [1] : 3, 0.013% ## low counts [2] : 0, 0% ## (mean count &lt; 3) ## [1] see &#39;cooksCutoff&#39; argument of ?results ## [2] see &#39;independentFiltering&#39; argument of ?results The genes with an adjusted p-value, padj, less than a threshold, say 0.1, provide a set that is expected to control its nominal FDR, for example no more than 10% of the genes in such a set on average should be false positives. We can look at the top lines of the results table. Note that DESeq2 does not sort the table, this must be done by the user. The top three lines correspond to the first three genes in the dataset unless the user performs an ordering operation. head(res, 3) ## log2 fold change (MLE): lineOCT4.conditiontrt ## Wald test p-value: lineOCT4.conditiontrt ## DataFrame with 3 rows and 6 columns ## baseMean log2FoldChange ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000000001.4 2182.07119024821 -0.00287371038033566 ## ENSMUSG00000000028.15 1210.75697410244 0.0517726930742058 ## ENSMUSG00000000031.16 4641.52905162061 1.28151815488918 ## lfcSE stat ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000000001.4 0.205255310240364 -0.0140006627695547 ## ENSMUSG00000000028.15 0.129112515641528 0.4009889577084 ## ENSMUSG00000000031.16 0.620842206786997 2.06416081393908 ## pvalue padj ## &lt;numeric&gt; &lt;numeric&gt; ## ENSMUSG00000000001.4 0.988829452275466 0.996690628108009 ## ENSMUSG00000000028.15 0.688428253763783 0.888527269357877 ## ENSMUSG00000000031.16 0.0390024715237021 0.195436116895824 For example, I can order adjusted p-values from small to large (but then remember that this object is no long aligned with rows of dds for example). res.ord &lt;- res[order(res$padj),] I will show how to examine the differences across all genes in an MA-plot. But first, I will compute a new estimate of fold change. The estimate in the results table above is the MLE, or maximum likelihood estimate, which is highly variable for low count genes (as we saw in the simulated example). Here I compute a Bayesian estimate for the fold change using methods in the apeglm package (Zhu, Ibrahim, and Love 2018). The apeglm functions are wrapped up in a DESeq2 function called lfcShrink, which produces a table similar to results but with shrunken LFC instead of MLE. library(apeglm) lfc &lt;- lfcShrink(dds, coef=&quot;lineOCT4.conditiontrt&quot;, type=&quot;apeglm&quot;) ## using &#39;apeglm&#39; for LFC shrinkage. If used in published research, please cite: ## Zhu, A., Ibrahim, J.G., Love, M.I. (2018) Heavy-tailed prior distributions for ## sequence count data: removing the noise and preserving large differences. ## Bioinformatics. https://doi.org/10.1093/bioinformatics/bty895 Another option for shrinkage is to specify type=&quot;ashr&quot; which will make use of the ashr package for shrinkage of effect sizes, with methods described by Stephens (2016). We can now examine the differences between the MLE and the Bayesian estimate of fold change from apeglm. First the MLE: plotMA(res, ylim=c(-4,4), colNonSig=&quot;grey60&quot;, colSig=&quot;blue&quot;, colLine=&quot;grey40&quot;) The genes passing a 10% FDR threshold are colored in blue. Note the wide variability on the left side of the plot. This is mostly due to imprecision in our estimates. After applying the Bayesian shrinkage procedure, the variability due to imprecision on the left side of the plot is reduced. In the paper by Zhu, Ibrahim, and Love (2018), it is demonstrated that the shrunken LFC are better suited for ranking genes by effect size. plotMA(lfc, ylim=c(-4,4), colNonSig=&quot;grey60&quot;, colSig=&quot;blue&quot;, colLine=&quot;grey40&quot;) For ranking genes by effect size, one would rank by abs(log2FoldChange) (with decreasing=TRUE), instead of by padj. In the next series of code chunks, I demonstrate how to add additional identifiers, such as gene symbols, to the MA-plot. I will select a subset of genes to add labels, here filtering the results table to a set of genes based on baseMean and log2FoldChange (these choices are arbitrary, solely for demonstration). For a given experiment, it would make more sense to pick out relevant genes by both significance, effect size, and biological interpretation. Because I have not re-ordered the lfc results table, I can add the SYMBOL column from the dds object to the results table, and then create a smaller table with our genes of interest. lfc$SYMBOL &lt;- mcols(dds)$SYMBOL tab &lt;- lfc %&gt;% as.data.frame %&gt;% filter(between(baseMean, 1e4, 1e5), between(abs(log2FoldChange), 1, 4)) tab &lt;- tab[complete.cases(tab),] I now highlight the genes in tab using the points and text functions. plotMA(lfc, ylim=c(-4,4), colNonSig=&quot;grey60&quot;, colSig=&quot;blue&quot;, colLine=&quot;grey40&quot;) with(tab, { points(baseMean, log2FoldChange, cex=2, col=&quot;blue&quot;) text(baseMean, log2FoldChange, SYMBOL, pos=4, col=&quot;blue&quot;) }) That worked, although it’s not easy to see the labels for a set of overlapping points below the horizontal axis. I can make a nicer looking plot using ggplot2. First I create a data frame that I will pass to the ggplot function. dat &lt;- as.data.frame(lfc) dat &lt;- dat[complete.cases(dat),] dat &lt;- dat %&gt;% mutate(sig = ifelse(padj &lt; .1, &quot;Y&quot;, &quot;N&quot;)) tab$sig &lt;- &quot;Y&quot; The following ggplot code chunk recreates the MA-plot that is built into DESeq2, but also uses the ggrepel package to make sure the point labels for our genes of interest do not overlap: library(ggplot2) library(ggrepel) ggplot(dat, aes(baseMean, log2FoldChange, col=sig, label=SYMBOL)) + geom_point() + scale_x_log10() + xlab(&quot;mean of normalized counts&quot;) + ylab(&quot;log fold change&quot;) + geom_hline(yintercept=0, col=&quot;grey40&quot;) + scale_color_manual(values=c(&quot;grey60&quot;, &quot;blue&quot;)) + geom_point(data=tab, shape=1, size=5, show.legend=FALSE) + geom_label_repel(data=tab, nudge_x = 1, nudge_y = 2*sign(tab$log2FoldChange), show.legend=FALSE) 2.3 Hypothesis weighting In the last series of code chunks, I will demonstrate the use of Independent Hypothesis Weighting (IHW) (Ignatiadis et al. 2016), in lieu of the more simplistic mean count filtering that is used in results by default. Instead of finding a threshold on the mean of scaled counts that optimizes the number of rejected hypotheses following Benjamini-Hochberg correction (Benjamini and Hochberg 1995), the IHW package finds an optimal weighting of the hypotheses that maximizes power while still controlling the FDR. To use IHW instead of mean count thresholding, I pass the ihw function to the filterFun argument of results. A similar number of genes are detected as differentially expressed in this case. suppressPackageStartupMessages(library(IHW)) res.ihw &lt;- results(dds, name=&quot;lineOCT4.conditiontrt&quot;, filterFun=ihw) summary(res.ihw) ## ## out of 23524 with nonzero total read count ## adjusted p-value &lt; 0.1 ## LFC &gt; 0 (up) : 1630, 6.9% ## LFC &lt; 0 (down) : 1974, 8.4% ## outliers [1] : 3, 0.013% ## [1] see &#39;cooksCutoff&#39; argument of ?results ## see metadata(res)$ihwResult on hypothesis weighting We can observe the weighting of hypotheses for various mean count ranges, across the cross-validation folds. For more details on the methods used here, consult the IHW package vignette and the publication by Ignatiadis et al. (2016). ihw.obj &lt;- metadata(res.ihw)$ihwResult plot(ihw.obj) Again, we can show that a similar set of genes were found in this case although in general the IHW procedure can outperform the simple filtering rules that results uses by default. table(filter=res$padj &lt; .05, IHW=res.ihw$padj &lt; .05) ## IHW ## filter FALSE TRUE ## FALSE 20616 145 ## TRUE 95 2665 References "],
["transcripts.html", "Chapter 3 Transcript expression", " Chapter 3 Transcript expression In the previous chapters, I showed importing transcript-level data with tximeta, summarizing the data to gene-level counts, and modeling the gene-level counts with DESeq2. Now I return to transcript-level data and demonstrate how we can perform statistical testing on transcripts, that is, across all the isoforms of all the genes. There are two important aspects to consider when performing transcript-level analysis: Uncertainty - Because the isoforms of a gene often have a considerable amount of sequence similarity resulting from shared exons, and because short read RNA-seq protocols involve generating fragments that do not span the entire transcript, there can be considerable uncertainty in assigning a given fragment to a particular transcript (see next chapter for a discussion of long read protocols). The uncertainty is not constant across the transcripts, and depends on many factors, some inherent to the gene model, such as the size of the alternative exons, and some inherent to the experiment, such as the sequencing depth, fragment length, read length, and technical biases producing non-uniform coverage. Isoform switching - We may perform testing for differential expression of each transcript (I will perform this analysis in this chapter), or we may also consider testing whether the usage of the isoforms within a gene changes across condition. The latter question is often termed differential transcript usage (DTU), and can be related to differential transcript expression (DTE), but they are not identical questions. For example, if all of the isoforms of a gene increase in their expression across condition with equal fold change, this is an example of differential gene expression (DGE) and DTE, but not DTU, as the proportions of the individual isoforms did not change. Regarding isoform switching, one reference which explores Bioconductor packages that can be used to detect DTU is the rnaseqDTU Bioconductor workflow (Love, Soneson, and Patro 2018). This workflow demonstrates optimal filtering techniques (Soneson et al. 2016), how the methods DEXSeq (Anders, Reyes, and Huber 2012) and DRIMSeq (Nowicka and Robinson 2016) can be applied to estimated transcript counts, and how stageR (Van den Berge et al. 2017) can be utilized to detect which genes and which isoforms contain evidence of DTU while controlling overall error rates. I will first introduce the experimental data, and then discuss various approaches used to analyze transcript-level data. I will load some processed RNA-seq data from an experiment by Alasoo et al. (2018), a subset of which is available in the macrophage Biconductor package. The experiment involved measuring transcription in macrophage cell lines from a number of human donors, both untreated, as well as treated with IFNg, Salmonella, and IFNg combined with Salmonella. Here I will focus on the samples that were untreated and treated with IFNg. As each cell line was from a human donor, I will also control for a baseline donor effect when comparing across treatment. The macrophage dataset has paired samples from 6 of the donors (all female), and has been quantified using Salmon. One unique aspect of Salmon is that it allows for GC bias correction at the fragment level during quantification, which is critical for reliable identification of the correct expressed isoform in experiments that have non-uniform coverage along the transcripts (Love, Hogenesch, and Irizarry 2016; Patro et al. 2017). Here I will perform differential transcript expression (DTE) analysis. A key aspect, compared to gene-level analysis, is that there is much more uncertainty in the assignments of fragments to transcripts. A number of statistical methods have been proposed to take this measurement uncertainty into account when performing downstream testing, including BitSeq (Glaus, Honkela, and Rattray 2012), mmdiff (Turro, Astle, and Tavaré 2013), IsoDE (Al Seesi et al. 2014), and Sleuth (Pimentel et al. 2017), the latter which leverages bootstrap quantification estimates from the kallisto (Bray et al. 2016) quantification method. These methods incorporate measurement uncertainty into parametric models for differential expression where biological variability is also modeled. The exception is IsoDE which compares bootstrap distributions of transcript expression for two samples at a time. Here, I will use a nonparametric method that takes into account both inferential uncertainty of fragment assignments, as well as biological variability across samples, called Swish (Zhu et al. 2019), which is available in the fishpond Bioconductor package. Swish stands for “SAMseq With Inferential Samples Helps”, as it is based on the existing statistical method for differential gene expression, SAMseq (Li and Tibshirani 2011). The key idea is to make use of nonparametric testing methods such as the Mann-Whitney Wilcoxon statistic, which operate only on the ranks of the data across samples. The original SAMseq method performed resampling of the counts in order to account for sequencing depth differences. Here, Swish will make use of multiple values in each cell of the count matrix that were computed by the Salmon software, using a technique called Gibbs sampling. For more details on the Gibbs sampling procedure, consult the publication of Salmon (Patro et al. 2017) and mmseq (Turro et al. 2011). Finally, the false discovery rate of the test statistics averaged over the multiple versions (or “inferential replicates”) of the counts matrix is computed via a permutation technique (Storey and Tibshirani 2003). I begin by locating the files in the macrophage package. As before, this step is not useful for a typical RNA-seq workflow, as the data will not be contained in an R package, but contained in some directory on a server or compute cluster. In lieu of the system.file command below, you should just specify the dir variable to be a path to the files, e.g. /path/to/data/dir. dir &lt;- system.file(&quot;extdata&quot;, package=&quot;macrophage&quot;) list.files(dir) ## [1] &quot;coldata.csv&quot; ## [2] &quot;errs&quot; ## [3] &quot;gencode.v29_salmon_0.12.0&quot; ## [4] &quot;gencode.v29.annotation.gtf.gz&quot; ## [5] &quot;PRJEB18997.txt&quot; ## [6] &quot;quants&quot; ## [7] &quot;supp_table_1.csv&quot; ## [8] &quot;supp_table_7.csv&quot; I then read in the sample table, and use dplyr to select certain columns, convert columns into factors, and add a new column pointing to the quantification files. library(readr) library(dplyr) coldata &lt;- read_csv(file.path(dir,&quot;coldata.csv&quot;)) ## Parsed with column specification: ## cols( ## names = col_character(), ## sample_id = col_character(), ## line_id = col_character(), ## replicate = col_double(), ## condition_name = col_character(), ## macrophage_harvest = col_character(), ## salmonella_date = col_character(), ## ng_ul_mean = col_double(), ## rna_extraction = col_character(), ## rna_submit = col_character(), ## library_pool = col_character(), ## chemistry = col_character(), ## rna_auto = col_double() ## ) lvls &lt;- c(&quot;naive&quot;,&quot;IFNg&quot;,&quot;SL1344&quot;,&quot;IFNg_SL1344&quot;) coldata &lt;- coldata %&gt;% dplyr::select(names, id=sample_id, line=line_id, condition=condition_name) %&gt;% mutate(line=factor(line), condition=factor(condition, levels=lvls), files=file.path(dir, &quot;quants&quot;, names, &quot;quant.sf.gz&quot;)) I will only consider for this demonstration the untreated and IFNg treated samples: coldata &lt;- coldata %&gt;% filter(condition %in% c(&quot;naive&quot;,&quot;IFNg&quot;)) coldata$condition &lt;- droplevels(coldata$condition) The coldata sample table now looks like: head(coldata) ## # A tibble: 6 x 5 ## names id line condition files ## &lt;chr&gt; &lt;chr&gt; &lt;fct&gt; &lt;fct&gt; &lt;chr&gt; ## 1 SAMEA103… diku_A diku… naive /Library/Frameworks/R.framewo… ## 2 SAMEA103… diku_B diku… IFNg /Library/Frameworks/R.framewo… ## 3 SAMEA103… eiwy_A eiwy… naive /Library/Frameworks/R.framewo… ## 4 SAMEA103… eiwy_B eiwy… IFNg /Library/Frameworks/R.framewo… ## 5 SAMEA103… fikt_A fikt… naive /Library/Frameworks/R.framewo… ## 6 SAMEA103… fikt_B fikt… IFNg /Library/Frameworks/R.framewo… Test that all the files exist as I specified: all(file.exists(coldata$files)) ## [1] TRUE As before, I use tximeta to read in the quantification data. This time I do not set dropInfReps=TRUE, as I will need the inferential replicates created by Salmon to perform DTE with Swish. The inferential replicates allows the analysis to take into account the uncertainty of fragment assignment to transcripts. library(tximeta) suppressPackageStartupMessages(library(SummarizedExperiment)) y &lt;- tximeta(coldata) ## importing quantifications ## reading in files with read_tsv ## 1 2 3 4 5 6 7 8 9 10 11 12 ## found matching linked transcriptome: ## [ GENCODE - Homo sapiens - release 29 ] ## loading existing TxDb created: 2019-02-11 14:22:51 ## loading existing transcript ranges created: 2019-05-31 20:37:15 ## fetching genome info for GENCODE For speed of the demonstration, I subset to only the transcripts on chromosome 1 (this would not be recommended for a typical analysis). y &lt;- y[seqnames(y) == &quot;chr1&quot;,] I load the fishpond package, which contains the methods for running Swish. There are three basic steps: scaling of the inferential replicates to make them comparable despite different sequencing depth, filtering out lowly expressed transcripts, and the testing itself. The scaling method by default uses the median ratio method of DESeq (Anders and Huber 2010). The labelKeep function by default will keep those transcripts with 3 or more samples with a count of 10 or higher. For scRNA-seq with UMI de-duplication, it is recommended to lower the minimal count to a lower value such as 3. The minimal number of samples can be increased for experiments with many samples. library(fishpond) y &lt;- scaleInfReps(y, quiet=TRUE) y &lt;- labelKeep(y) y &lt;- y[mcols(y)$keep,] Because the method makes use of permutations, it is required to set a seed for computational reproducibility. I specify to test across the condition variable, while controlling for a pairing variable line. The line variable indicates which donor the cell line came from. set.seed(1) y &lt;- swish(y, x=&quot;condition&quot;, pair=&quot;line&quot;, quiet=TRUE) After running swish, all of the results are stored in the metadata columns (mcols) of the object y. I look to see how many transcripts have a small q-value (analogous to an adjusted p-value, this should provide a set with a nominal FDR control). names(mcols(y)) ## [1] &quot;tx_id&quot; &quot;gene_id&quot; &quot;tx_name&quot; &quot;log10mean&quot; &quot;keep&quot; ## [6] &quot;stat&quot; &quot;log2FC&quot; &quot;pvalue&quot; &quot;locfdr&quot; &quot;qvalue&quot; table(mcols(y)$qvalue &lt; .05) ## ## FALSE TRUE ## 5081 1329 One important aspect in testing across many features, in particular where the uncertainty level is so heterogeneous, is to consider if the p-value distribution is roughly uniform, with the exception of the rejected tests. Here Swish provides a roughly uniform distribution, with a spike on the left side representing the rejections of the null hypothesis. hist(mcols(y)$pvalue, col=&quot;grey&quot;, main=&quot;&quot;, xlab=&quot;p-values&quot;) As with DESeq2 I can make an MA-plot, with the differential transcripts highlighted in blue (here at 5% FDR). plotMASwish(y, alpha=.05) I can also examine individual transcripts with evidence of differential expression. As each sample is represented by a distribution of possible estimated counts from Salmon, Swish uses boxplots to represent the differences in expression across samples: idx &lt;- with(mcols(y), which(pvalue &lt; .05 &amp; log2FC &gt; 4)) plotInfReps(y, idx[1], x=&quot;condition&quot;, cov=&quot;line&quot;, xaxis=FALSE) This chapter gives a basic introduction to DTE using nonparametric testing with the Swish method. For more details on transcript-level analysis, it is recommended to consult the fishpond Bioconductor package vignette, or the rnaseqDTU workflow on Bioconductor (Love, Soneson, and Patro 2018). References "],
["limits.html", "Chapter 4 Limitations and extensions", " Chapter 4 Limitations and extensions In this final chapter, I discuss limitations to the methods presented earlier, and extensions for analyzing high dimensional counts in contexts beyond what was previously covered. Single cell RNA-seq - The DESeq2 framework shown in the gene-level analysis chapter was designed for bulk RNA-seq, in which the Negative Binomial GLM assessing differences across samples was suitable both in terms of distribution and in terms of answering many biological questions of interest. In single cell RNA-seq, there are new considerations and questions of interest. One aspect is that, with UMI barcoding, there is a need for quantification methods that resolve errors and de-duplicate the read data into molecule counts per cell. The alevin method (A. Srivastava, Malik, Smith, et al. 2019), packaged within the Salmon software, can accomplish this UMI de-duplication, and can resolve the increased rate of multi-mapping reads seen in 3’ tagged sequencing, through an approach similar to that taken by Salmon. The quantification from alevin can be easily imported into R/Bioconductor using the tximeta software seen in the quantification chapter. After quantification, there are many choices regarding the analysis pipeline, I refer to recent reviews for systematic comparison. Soneson and Robinson (2018) evaluates methods for detecting differences in expression across groups of cells. Sun et al. (2019) evaluates methods for dimension reduction, which is often performed in the context of cell clustering and lineage reconstruction. Duo, Robinson, and Soneson (2018) evaluates methods for clustering to recover sub-populations of cells. Finally, I note that the NB methods shown in the gene-level chapter can be combined with other statistical methods to add and model a zero component, in the case that the Negative Binomial is not a suitable distribution (Van den Berge et al. 2018). The zero component may not be needed for all scRNA-seq datasets however, in particular if UMI de-duplication is possible. Long reads - The data presented in previous sections involved sequencing relatively short sequences of the cDNA fragments. They sequences are short in the sense that they do not come close to capturing the entire sequence of the transcript for most mammalian transcripts. However, new technologies have emerged in the past decade that allow for high-throughput sequencing of lengths that approach the entire transcript length. This necessitates new methods for alignment (the long sequences nevertheless have a higher error rate than the “short” reads). One of the most popular methods for aligning long reads is minimap2 (Li 2018). Following alignment, it is possible to again quantify expression using Salmon and import the data into R/Bioconductor using tximeta. A systematic evaluation of quantification using the Nanopore long read technology has been performed by Soneson et al. (2019). Additionally, a pipeline for long read mapping with minimap2 and quantification with Salmon has been recently published with an associated GitHub repository (Cruz-Garcia et al. 2019). Genetic variation - An aspect not explored in the previous sections was genetic variation across the samples in the exonic sequence. One analysis of interest is to identify common genetic variants in the exonic sequence, and to quantify, among the samples that are heterozygous for a given exonic SNP, the expression of each allele. Best practices for allelic expression analysis have been presented by Castel et al. (2015), and an evaluation of EM-based methods for assessing allelic expression have been proposed and compared by Raghupathy et al. (2018). Aside from interest in quantifying allelic expression in the presence of heterozygous exonic positions, A. Srivastava, Malik, Sarkar, et al. (2019) have examined the effect of genetic variation on transcript and gene expression quantification. Microbiome - I have described here various methods for analyzing counts reflecting the abundance of RNA molecules across samples. Another type of high dimensional count dataset with similar but distinct analysis considerations is that produced in a microbiome or metagenomic study, in which the counts reflect the abundance of certain taxa across samples. The count data is arranged in a similar format to gene expression, but with the taxa replacing the transcripts or genes on the rows of the matrix. While many have considered using gene expression normalization and testing methods for analyzing this type of data, a number of the assumptions used in gene expression models may be invalid for particular microbiome datasets. In particular, I demonstrated in the first exploration of gene expression counts that there were thousands of features in which the changes from sample to sample were minimal. There was a clear center of the distribution of log fold changes that could be used to estimate the size factors for scaling normalization across samples. In particular microbiome studies, this assumption may not fit, as there may not be a group of taxa that can be assumed roughly equally abundant across all samples in a dataset. In addition, there may be too few taxa, such that the Poisson modeling assumption no longer makes sense, and so a compositional model may better capture the distributional properties (Fernandes et al. 2014). A recent benchmarking effort compares compositional methods as well as single cell RNA-seq methods for analyzing microbiome datasets for differences in abundance of taxa (Calgaro et al. 2020). Alternative pipelines for analyzing microbiome abundance data have been detailed by Callahan et al. (2016). There may be more interesting and relevant approaches to modeling the counts besides the GLM, and latent variable models are considered and applied to microbiome datasets recently by Sankaran and Holmes (2018). Finally, statistical considerations of various diversity measures for count-based microbiome studies have been explored recently by Willis (2019). References "],
["session.html", "Chapter 5 Session information", " Chapter 5 Session information sessionInfo() ## R version 3.6.1 (2019-07-05) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS Mojave 10.14.6 ## ## Matrix products: default ## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] parallel stats4 stats graphics grDevices datasets ## [7] utils methods base ## ## other attached packages: ## [1] fishpond_1.2.0 IHW_1.14.0 ## [3] ggrepel_0.8.1 ggplot2_3.2.1 ## [5] DESeq2_1.26.0 rafalib_1.0.0 ## [7] org.Mm.eg.db_3.10.0 AnnotationDbi_1.48.0 ## [9] SummarizedExperiment_1.16.0 DelayedArray_0.12.0 ## [11] BiocParallel_1.20.0 matrixStats_0.55.0 ## [13] Biobase_2.46.0 GenomicRanges_1.38.0 ## [15] GenomeInfoDb_1.22.0 IRanges_2.20.1 ## [17] S4Vectors_0.24.1 BiocGenerics_0.32.0 ## [19] tximeta_1.4.3 dplyr_0.8.3 ## [21] readr_1.3.1 bookdown_0.16 ## [23] testthat_2.3.1 rmarkdown_1.18 ## [25] devtools_2.2.1 usethis_1.5.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ## [3] rprojroot_1.3-2 htmlTable_1.13.3 ## [5] XVector_0.26.0 base64enc_0.1-3 ## [7] fs_1.3.1 rstudioapi_0.10 ## [9] farver_2.0.1 remotes_2.1.0 ## [11] bit64_0.9-7 fansi_0.4.0 ## [13] splines_3.6.1 tximport_1.14.0 ## [15] geneplotter_1.64.0 knitr_1.26 ## [17] pkgload_1.0.2 zeallot_0.1.0 ## [19] Formula_1.2-3 jsonlite_1.6 ## [21] Rsamtools_2.2.1 annotate_1.64.0 ## [23] cluster_2.1.0 dbplyr_1.4.2 ## [25] compiler_3.6.1 httr_1.4.1 ## [27] backports_1.1.5 assertthat_0.2.1 ## [29] Matrix_1.2-18 lazyeval_0.2.2 ## [31] cli_1.1.0 acepack_1.4.1 ## [33] htmltools_0.4.0 prettyunits_1.0.2 ## [35] tools_3.6.1 gtable_0.3.0 ## [37] glue_1.3.1 GenomeInfoDbData_1.2.2 ## [39] rappdirs_0.3.1 Rcpp_1.0.3 ## [41] slam_0.1-46 vctrs_0.2.0 ## [43] Biostrings_2.54.0 rtracklayer_1.46.0 ## [45] xfun_0.11 stringr_1.4.0 ## [47] ps_1.3.0 lifecycle_0.1.0 ## [49] ensembldb_2.10.2 gtools_3.8.1 ## [51] XML_3.98-1.20 zlibbioc_1.32.0 ## [53] scales_1.1.0 hms_0.5.2 ## [55] ProtGenerics_1.18.0 AnnotationFilter_1.10.0 ## [57] RColorBrewer_1.1-2 yaml_2.2.0 ## [59] curl_4.3 memoise_1.1.0 ## [61] gridExtra_2.3 biomaRt_2.42.0 ## [63] rpart_4.1-15 latticeExtra_0.6-28 ## [65] stringi_1.4.3 RSQLite_2.1.3 ## [67] genefilter_1.68.0 desc_1.2.0 ## [69] checkmate_1.9.4 GenomicFeatures_1.38.0 ## [71] pkgbuild_1.0.6 rlang_0.4.2 ## [73] pkgconfig_2.0.3 bitops_1.0-6 ## [75] lpsymphony_1.14.0 evaluate_0.14 ## [77] lattice_0.20-38 purrr_0.3.3 ## [79] labeling_0.3 htmlwidgets_1.5.1 ## [81] GenomicAlignments_1.22.1 bit_1.1-14 ## [83] processx_3.4.1 tidyselect_0.2.5 ## [85] magrittr_1.5 R6_2.4.1 ## [87] Hmisc_4.3-0 DBI_1.0.0 ## [89] pillar_1.4.2 foreign_0.8-72 ## [91] withr_2.1.2 survival_3.1-8 ## [93] RCurl_1.95-4.12 nnet_7.3-12 ## [95] tibble_2.1.3 crayon_1.3.4 ## [97] utf8_1.1.4 fdrtool_1.2.15 ## [99] BiocFileCache_1.10.2 progress_1.2.2 ## [101] locfit_1.5-9.1 grid_3.6.1 ## [103] data.table_1.12.6 blob_1.2.0 ## [105] callr_3.3.2 digest_0.6.23 ## [107] xtable_1.8-4 openssl_1.4.1 ## [109] munsell_0.5.0 sessioninfo_1.1.1 ## [111] askpass_1.1 "],
["references.html", "Chapter 6 References", " Chapter 6 References "]
]
